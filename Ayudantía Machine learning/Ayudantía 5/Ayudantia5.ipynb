{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "(Agradecimientos a Pavlos Protopapas (Harvard U.), Manuel Pérez y Guille Cabrera (UdeC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Recordando, la regresión logística para clasificación funciona mucho mejor cuando las clases se encuentran bien separadas dentro del espacio de características (feature space) y el límite de decisión (decision boundary) puede ser definido por una ecuación:\n",
    "\n",
    "$f(x1,...,xJ) = 0$\n",
    "\n",
    "\n",
    "El siguiente es un dataset tipico para regresión logistica con un límite de decisión lineal: \n",
    "\n",
    "\n",
    "<img src=\"https://www.cntk.ai/jup/cancer_classify_plot.jpg\">\n",
    "\n",
    "Mientras los modelos de regresión logística con límites de decisión lineales son intuitivos y fáciles de interpretar al observar el límite de decisión de cada predictor, es muy dificil de interpretar limites de decisión no lineales:\n",
    "\n",
    "\n",
    "$(x_{3} +2x_{2})^{2} −x_{1} +10 = 0$\n",
    "\n",
    "\n",
    "Sería deseable construir modelos con límites de decisión complejos que también sean fáciles de interpretar, pues como humanos, siempre intentamos buscar modelos interpretables para diferenciar entre clases de objetos y fenómenos:\n",
    "\n",
    "<img src=\"http://dataaspirant.com/wp-content/uploads/2017/01/B03905_05_01-compressor.png\">\n",
    "\n",
    "\n",
    "Resulta que los diagramas de flujo simples como el del ejemplo, pueden formularse como modelos matemáticos para la clasificación y estos modelos tienen las propiedades que deseamos:\n",
    "1. Interpretabilidad\n",
    "2. Límites de decisión más complejos\n",
    "3. Límites de decisión localmente lineales, donde cada componente del limite de decisión es simple de describir matemáticamente.\n",
    "\n",
    "\n",
    "La idea detrás de los árboles de regresión es dividir iterativamente el espacio de coordenadas linealmente en diferentes regiones. Asociamos un número real a cada hoja del árbol. El valor de cada hoja se obtiene al minimizar el error al cuadrado\n",
    "\n",
    "$\\hat{f}(x) = \\mathrm{argmin}_y\\sum_{i|x_i\\in R(x)}(y-y_i)^2$, donde $R(x)$ es la región (u hoja) donde $x$ miente. \n",
    "Optimizando esa expresión simple, se puede demostrar que el valor regresivo constante para cada región es solo el promedio de los valores $y_i$ de las instancias que caen en esa región.\n",
    "\n",
    "<img src = images/TreeRegression.png/>\n",
    "\n",
    "Dado un arbol $T$, la suma cuadrada de los errores es:\n",
    "\\begin{equation}\n",
    "S = \\sum_{c\\in\\mathrm{leaves}(T)}\\sum_{i\\in c} (y_i - m_c)^2.\n",
    "\\end{equation}\n",
    "\n",
    "Cada nodo es determinado dividiendo el espacio coordenado en el sentido que se minimize el error.\n",
    "\n",
    "#### Algoritmo:\n",
    "\n",
    "* Empezar con un único nodo que contiene todos los puntos. Calcular $m_c$ (espacio) and $S$ (error).\n",
    "* Si (todos los puntos en el nodo tienen el mismo valor para todas las variables independientes):\n",
    "  * stop\n",
    "* Sino:\n",
    "  * buscar sobre todas las divisiones binarias de todas las variables, tal que estas reduzcan $S$ tanto como sea posible. \n",
    "  * Si (la mayor disminución en $ S $ es menor que algún umbral $ \\ delta $) o (uno de los nodos resultantes\n",
    "Contiene menos de $ q $ puntos)\n",
    "    * stop\n",
    "  * Sino:\n",
    "    * Tomar esa división y crear dos nuevos nodos.\n",
    "  * Para cada nuevo nodo:\n",
    "      Repetir el procedimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The wine aficionado\n",
    "\n",
    "¿Puede un productor de vino predecir cómo se recibirá un vino en función de las propiedades químicas de éste? ¿Hay indicadores químicos que se correlacionen más fuertemente con la \"calidad\" percibida de un vino?\n",
    "\n",
    "Examinamos el conjunto de datos de calidad del vino alojado en el <a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Quality\"> sitio web de UCI </a>. Estos datos registran 11 propiedades químicas (como las concentraciones de azúcar, ácido cítrico, alcohol, pH, etc.) de miles de vinos tintos y blancos del norte de Portugal, así como la calidad de los vinos, registrados en una escala del 1 al 10. En este problema, solo veremos los datos de vino tinto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.winemaniacs.com/wp-content/uploads/2013/04/WineRotator-2000x925.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10237fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "plt.hist(df.quality)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Utilizaremos la columna de calidad como nuestra variable objetivo. Excepto que simplificaremos el problema a un mundo binario en el que los vinos son \"malos\" (puntuación <7 puntuación <7) o \"buena\" (puntuación> 7) puntuación≥7). Por ejemplo, si originalmente Y = [1,3,8,4,7] Y = [1,3,8,4,7], el nuevo YY debería ser [0,0,1,0,1] [0 , 0,1,0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "Y = df['quality'].values\n",
    "df_tmp = df.drop('quality',1)\n",
    "Y = np.array([1 if y>=7 else 0 for y in Y])\n",
    "X = df_tmp.as_matrix()\n",
    "\n",
    "df['target'] = (df['quality'].values >=7)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103480a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un problema en el cual las clases están desbalanceadas, por lo cual una buena medida de error puede ser \n",
    "f1-score. Recordando:\n",
    "\n",
    "donde $TP$=True Positive, $FN$= False Negative...etc\n",
    "\n",
    "**recall**\n",
    "$$\\text{recall} = \\frac{TP}{P}=\\frac{TP}{TP+FN}.$$\n",
    "**precision**\n",
    "$$\\text{precision} = \\frac{TP}{TP+FP}.$$\n",
    "F1-Score es la combinación entre ambas medidas de error:\n",
    "$$F_1 = \\frac{2\\times\\text{recall}\\times\\text{precision}}{\\text{recall} + \\text{precision}}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de un árbol de decisión\n",
    "\n",
    "Construir un árbol de decisiones no es mucho más difícil que leer uno, aquí está el resumen esencial:\n",
    "\n",
    "Digamos que estamos construyendo un árbol de clasificación al considerar una lista de predictores. En nuestro ejemplo anterior, queremos poder clasificar los buenos vinos del resto usando cosas como la acidez fija, el pH, el alcohol, etc. Todas estas son variables continuas, genéricamente las llamaremos $ X_{i1}, X_{i2},. .., X_{ip} $ ($ i $ para vino, $ p $ para predictores). También tenemos una etiqueta observada $ Y_i $ por cada vino.\n",
    "\n",
    "Primero asignamos a todos a la misma clase, digamos $ \\hat{Y_i} = 1 $. Podemos calcular el error al cuadrado $ Err = \\sum_i {(\\hat{Y_i} - Y_i) ^ 2} $\n",
    "\n",
    "- En ** cada paso ** del algoritmo, consideramos una lista de posibles decisiones (o divisiones), por ejemplo, $ X_{10}> 12 $, es decir, el contenido de alcohol es superior al 12%.\n",
    "- Para cada decisión posible recalculamos el predictor para esa regla, por ejemplo $ \\hat{Y_i} = 1 $ si $ X_ {10}> 12 $ y $ 0 $ de lo contrario.\n",
    "- Recalculamos el error para cada posible decisión: $ Err = \\sum_i {(\\hat{Y_i} - Y_i) ^ 2} $\n",
    "- Elegimos la decisión que reduce el error por la cantidad más grande\n",
    "- Entonces sigue ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-61dffa6aa122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStringIO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import io\n",
    "from sklearn.tree import export_graphviz\n",
    "from StringIO import StringIO\n",
    "\n",
    "# https://github.com/JWarmenhoven/ISLR-python\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "    tree = estimator\n",
    "    names = features\n",
    "    color = filled\n",
    "    classn = class_names\n",
    "    \n",
    "    dot_data = io.StringIO()\n",
    "    export_graphviz(estimator, out_file=dot_data, feature_names=features, proportion=True, class_names=classn, filled=filled)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score en el set de entrenamiento: 0.07\n",
      "f1-score en el set de prueba:     0.05\n",
      "[[409   0]\n",
      " [ 69   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "subdf=df[['sulphates', 'fixed acidity']]\n",
    "X=subdf.values\n",
    "Y=df['target'].values\n",
    "\n",
    "clfTree1 = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3, random_state=77)\n",
    "\n",
    "clf=clfTree1.fit(Xtrain, ytrain)\n",
    "\n",
    "training_score = f1_score(clf.predict(Xtrain), ytrain)\n",
    "test_score = f1_score(clf.predict(Xtest), ytest)\n",
    "print(\"f1-score en el set de entrenamiento: %0.2f\" % (training_score))\n",
    "print(\"f1-score en el set de prueba:     %0.2f\" % (test_score))\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph3 = print_tree(clf, features=['alcohol', 'sulphates'], class_names=['No', 'Yes'])\n",
    "#Image(graph3.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = images/Tree.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "\n",
    "Random Forest funciona al agregar los resultados de una serie de árboles de decisión alterados aleatoriamente construidos para explicar los datos.\n",
    "\n",
    "### Un poco de bootstrap aggregation\n",
    "\n",
    "La idea de Random Forest surge de manera natural al considerar un Tree bagging. En Tree bagging hacemos lo siguiente $ b $ veces:\n",
    "\n",
    "1. Tomar una submuestra aleatoria de los datos.\n",
    "2. Construir un arbol de clasificación (regresión) como en la sección previa\n",
    "3. Repetir\n",
    "\n",
    "Para un nuevo dato, podemos simplemente ejecutar ese punto a través de todos los árboles $ b $ construidos, obtener todas las decisiones $ \\hat{Y_1}, ..., \\hat{Y_b} $ y obtener la mayoría de los votos. Esta forma de promediar elimina algunos de los problemas de ajuste que se encuentran en el uso de un solo árbol. Además, ajustar estos árboles cuesta mucho computacionalmente, entonces, ¿qué más podemos hacer?\n",
    "\n",
    "\n",
    "### Random Forests\n",
    "Este método es muy similar al método de agregación bootstrap. Sin embargo, como su nombre indica, se inyecta algo de aleatoriedad adicional en la construcción de los árboles. Resulta que los árboles que se construyen a partir de la submuestra aleatoria de sus datos son bastante similares, por lo que la solución es bastante simple. En Random Forests hacemos los siguientes $ b $ veces:\n",
    "\n",
    "1. Tomar una submuestra aleatoria de los datos.\n",
    "2. Elegir aleatoriamente un numero de predictores a ser utilizados en la construcción del árbol.\n",
    "3. Construir un árbol de clasificación (o regresión) sólo con las variables seleccionadas en 2.\n",
    "4. Repetir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score en el set de entrenamiento: 0.85\n",
      "f1-score en el set de prueba:     0.35\n",
      "[[389  20]\n",
      " [ 52  19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "clfForest = RandomForestClassifier(n_estimators=10, oob_score=True, max_features='auto')\n",
    "clf=clfForest.fit(Xtrain, ytrain)\n",
    "\n",
    "training_score = f1_score(clf.predict(Xtrain), ytrain)\n",
    "test_score = f1_score(clf.predict(Xtest), ytest)\n",
    "print(\"f1-score en el set de entrenamiento: %0.2f\" % (training_score))\n",
    "print(\"f1-score en el set de prueba:     %0.2f\" % (test_score))\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con todas las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df['quality'].values\n",
    "Y = np.array([1 if y>=7 else 0 for y in Y])\n",
    "X = df.loc[:, :'alcohol'].values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score en el set de entrenamiento: 0.45\n",
      "f1-score en el set de prueba:     0.49\n",
      "[[403   6]\n",
      " [ 46  25]]\n"
     ]
    }
   ],
   "source": [
    "clfTree1 = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3, random_state=77)\n",
    "\n",
    "clf = clfTree1.fit(Xtrain, ytrain)\n",
    "\n",
    "training_score = f1_score(clf.predict(Xtrain), ytrain)\n",
    "test_score = f1_score(clf.predict(Xtest), ytest)\n",
    "print(\"f1-score en el set de entrenamiento: %0.2f\" % (training_score))\n",
    "print(\"f1-score en el set de prueba:     %0.2f\" % (test_score))\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score en el set de entrenamiento: 0.98\n",
      "f1-score en el set de prueba:     0.40\n",
      "[[403   6]\n",
      " [ 52  19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "clfForest = RandomForestClassifier(n_estimators=10, oob_score=True, max_features='auto')\n",
    "clf=clfForest.fit(Xtrain, ytrain)\n",
    "\n",
    "training_score = f1_score(clf.predict(Xtrain), ytrain)\n",
    "test_score = f1_score(clf.predict(Xtest), ytest)\n",
    "print(\"f1-score en el set de entrenamiento: %0.2f\" % (training_score))\n",
    "print(\"f1-score en el set de prueba:     %0.2f\" % (test_score))\n",
    "print(confusion_matrix(ytest, clf.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Podemos Mejorarlo más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this, but carefully pal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_score = f1_score(rf_random.predict(Xtrain), ytrain)\n",
    "test_score = f1_score(rf_random.predict(Xtest), ytest)\n",
    "print(\"f1-score en el set de entrenamiento: %0.2f\" % (training_score))\n",
    "print(\"f1-score en el set de prueba:     %0.2f\" % (test_score))\n",
    "print(confusion_matrix(ytest, rf_random.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
