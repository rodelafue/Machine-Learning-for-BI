{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayudantía 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ayudantía veremos los siguientes tópicos:\n",
    "- Conceptos de objeto\n",
    "- Ejemplos de Pipeline, Scalers y Cross-validation\n",
    "- uso de pandas\n",
    "- metricas de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demostración de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I demonstrate several key features of classes and object-oriented programming in Python.  These include the following\n",
    "- class inheritance\n",
    "- overriding magic methods\n",
    "- property setters and getters (using `@property` and `@<attribute>.setter` decorators)\n",
    "- composition\n",
    "\n",
    "These examples were inspired by the simple straight-forward book [\"Object-Oriented Programming in Python\"](http://python-textbok.readthedocs.io/en/stable/index.html) written for a MSc-level \n",
    "course in IT at the University of Cape Town.  The copyright of the book is held by University of Cape Town and individual contributors and has been released under the CC BY-SA 4.0 licence. Revision 8e685e710775+. \n",
    "\n",
    "Note that I will add more description as time permits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by defining a Person class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Person(object):\n",
    "    \n",
    "    def __init__(self, name, surname, gender, birthdate, **kwargs):\n",
    "        self.name = name\n",
    "        self.surname = surname\n",
    "        self.birthdate = birthdate\n",
    "        if 'male' == gender.lower() or 'boy' == gender.lower():\n",
    "            self.gender = 'male'\n",
    "        else:\n",
    "            self.gender = 'female'\n",
    "        # accomodate other input information\n",
    "        for key, val in kwargs.items():\n",
    "            self.__dict__[key] = val\n",
    "\n",
    "    @property\n",
    "    def fullname(self):\n",
    "        return '{} {}'.format(self.name, self.surname)\n",
    "\n",
    "    @property\n",
    "    def age(self):\n",
    "        today = datetime.date.today()\n",
    "        age = today.year - self.birthdate.year\n",
    "\n",
    "        if today < datetime.date(today.year, self.birthdate.month, self.birthdate.day):\n",
    "            age -= 1\n",
    "        return age\n",
    "\n",
    "    # override some magic methods\n",
    "\n",
    "    def __str__(self):\n",
    "        critical_keys = ['name', 'surname', 'gender', 'birthdate', 'fullname']\n",
    "        about = '\\n{} is a {}-y-o {}.\\n'.format(self.fullname, self.age,\n",
    "                                                self.gender)\n",
    "        additional_keys = list(set(self.__dict__.keys()) - set(critical_keys))\n",
    "        if len(additional_keys) > 0:\n",
    "            about += '--Additional info--\\n'\n",
    "            for key in additional_keys:\n",
    "                about += '{}: {}\\n'.format(key, self.__dict__[key])\n",
    "        return about\n",
    "\n",
    "    # setup comparison based on name alphabatization\n",
    "    def __eq__(self, other): # does self == other?\n",
    "        return self.name == other.name and self.surname == other.surname\n",
    "\n",
    "    def __gt__(self, other): # is self > other?\n",
    "        if self.surname == other.surname:\n",
    "            return self.name > other.name\n",
    "        return self.surname > other.surname\n",
    "\n",
    "    # now we can define all the other methods in terms of the first two\n",
    "    def __ne__(self, other): # does self != other?\n",
    "        return not self == other # this calls self.__eq__(other)\n",
    "\n",
    "    def __le__(self, other): # is self <= other?\n",
    "        return not self > other # this calls self.__gt__(other)\n",
    "\n",
    "    def __lt__(self, other): # is self < other?\n",
    "        return not (self > other or self == other)\n",
    "\n",
    "    def __ge__(self, other): # is self >= other?\n",
    "        return not self < other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expects certain critical input values when intantiating a person, their first and last name, gender, and birthdate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dawn = Person('Dawn', 'Joe', 'female', datetime.date(1984, 1, 13))\n",
    "print(dawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, I set this up to accept additional keyword arguments as well. This should be done with care as relying on these additional attributes can lead to problems if they are not populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jon = Person('Jon', 'Doe', 'male', datetime.date(1983, 8, 21),\n",
    "             email='jon.doe@email.com', address='123 Redwood Ct',\n",
    "             cell='249.298.6690', hair='red')\n",
    "print(jon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define a Child class. It will inherit from the Person class, with one added property, nap_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Child(Person):\n",
    "    \n",
    "    @property\n",
    "    def nap_time(self):\n",
    "        if self.age < 1:\n",
    "            return [9, 1]\n",
    "        elif self.age < 5:\n",
    "            return [1]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def __str__(self):\n",
    "        critical_keys = ['name', 'surname', 'gender', 'birthdate', 'fullname']\n",
    "        about = '{} is a {}-y-o {},\\n'.format(self.fullname, self.age,\n",
    "                                                self.gender)\n",
    "        if len(self.nap_time) > 1:\n",
    "            about += 'and takes naps at {} and {} o-clock.\\n'.format(*self.nap_time)\n",
    "        elif len(self.nap_time) > 0:\n",
    "            about += 'with a nap time at {} o-clock.\\n'.format(*self.nap_time)\n",
    "        else:\n",
    "            about += 'and is too old for naps.\\n'\n",
    "\n",
    "        additional_keys = list(set(self.__dict__.keys()) - set(critical_keys))\n",
    "        if len(additional_keys) > 0:\n",
    "            about += '--Additional info--\\n'\n",
    "            for key in additional_keys:\n",
    "                about += '{}: {}\\n'.format(key, self.__dict__[key])\n",
    "        return about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sussy = Child('Sussy', 'Doe', 'female', datetime.date(2011, 7, 22))\n",
    "print(sussy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "johnny = Child('Johnny', 'Doe', 'male', datetime.date(2015, 3, 1),\n",
    "               blankie='blue', hair='red', toy='green ball')\n",
    "print(johnny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already been using composition, by providing a datetime object for the birthdate input value but I will go one step further. Now I will define a basic family class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Family(object):\n",
    "\n",
    "    def __init__(self, mommy, daddy, *kids):\n",
    "        self.mommy = mommy\n",
    "        self.daddy = daddy\n",
    "        self.kids = list(kids)\n",
    "        self.number_of_kids = len(self.kids)\n",
    "\n",
    "    def __str__(self):\n",
    "        about = ('\\nThe {} family is made up of {}, {}, \\n'\n",
    "                 'and their {} kids: \\n'.format(self.daddy.surname,\n",
    "                                                self.daddy.name,\n",
    "                                                self.mommy.name,\n",
    "                                                self.number_of_kids))\n",
    "        for kid in self.kids:\n",
    "            about += '{name}\\n'.format(name=kid.name)\n",
    "\n",
    "        return about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use this to define a family from the four people I have already instantiated, Jon, Dawn, Sussy, and Johnny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_family = Family(dawn, jon, johnny, sussy)\n",
    "print(simple_family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will define a family that can add grow using the add_child method. I will implement this two different ways to illustrate the difference between lazy and eager calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LazyFamily(Family):\n",
    "\n",
    "    def __init__(self, mommy, daddy, *kids):\n",
    "        self.mommy = mommy\n",
    "        self.daddy = daddy\n",
    "        self.kids = list(kids)\n",
    "\n",
    "    @property\n",
    "    def family_size(self):\n",
    "        time.sleep(0.01)  # mimic a long calculation\n",
    "        return 2 + self.number_of_kids\n",
    "\n",
    "    @property\n",
    "    def number_of_kids(self):\n",
    "        time.sleep(0.01)  # mimic a long calculation\n",
    "        return len(self.kids)\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.kids.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alicia = Child('Alicia', 'Doe', 'female', datetime.date(2017, 7, 20))\n",
    "family_1 = LazyFamily(dawn, jon, johnny, sussy)\n",
    "print('before: {}'.format(family_1))\n",
    "\n",
    "family_1.add_child(alicia)\n",
    "print('after: {}'.format(family_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EagerFamily(Family):\n",
    "\n",
    "    def __init__(self, mommy, daddy, *kids):\n",
    "        self.mommy = mommy\n",
    "        self.daddy = daddy\n",
    "        self.kids = list(kids)\n",
    "        self._number_of_kids = len(self.kids)\n",
    "        self._family_size = 2 + self.number_of_kids\n",
    "\n",
    "    @property\n",
    "    def number_of_kids(self):\n",
    "        return self._number_of_kids\n",
    "    @number_of_kids.setter\n",
    "    def number_of_kids(self, val):\n",
    "        time.sleep(0.01)  # mimic a long calculation\n",
    "        self._number_of_kids = val\n",
    "\n",
    "    @property\n",
    "    def family_size(self):\n",
    "        return self._family_size\n",
    "    @family_size.setter\n",
    "    def family_size(self, val):\n",
    "        time.sleep(0.01)  # mimic a long calculation\n",
    "        self._family_size = val\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.kids.append(child)\n",
    "        self._number_of_kids = len(self.kids)\n",
    "        self._family_size = 2 + self.number_of_kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_2 = EagerFamily(dawn, jon, johnny, sussy)\n",
    "print('before: {}'.format(family_2))\n",
    "\n",
    "rosy = Child('Rosy', 'Doe', 'female', datetime.date(2017, 1, 19))\n",
    "family_2.add_child(rosy)\n",
    "print('after: {}'.format(family_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the surface, these two different Family definitions seems to perform the same function. They differ in how they are calculating some of the properties, particularly family_size and number_of_kids. In the LazyFamily, nothing is calculated until it is asked for. In the EagerFamily, the calculations are performed as soon the information is available then cached or stored until needed. In this example, the operations are fairly minimal, so I added a 10 ms sleep before the calculation in both family definitions. This provides a clear comparison between the timing results of the two different approaches.\n",
    "Here I query the family_size five times. In the lazy case, this means the computation to get the family_size must be performed five times instead of just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(n):\n",
    "    lazy_family_size = family_1.family_size\n",
    "t_lazy = time.time() - t0\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(n):\n",
    "    eager_family_size = family_2.family_size\n",
    "t_eager = time.time() - t0\n",
    "\n",
    "print(\"lazy family: {}s\".format(t_lazy))\n",
    "print(\"eager family: {}s\".format(t_eager))\n",
    "x_faster = t_lazy / t_eager\n",
    "print(\"eager family was {}x faster than the lazy family\".format(x_faster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how large of a difference this was!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or I can just use the %timeit magic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit family_1.family_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit family_2.family_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this confirms that for the eager case, the value only had to be computed once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial on how to compare machine learning methods with the python library scikit-learn. We'll be using the Indian Liver Disease dataset (found [here](https://www.kaggle.com/uciml/indian-liver-patient-records)).\n",
    "\n",
    "From the dataset page:\n",
    "\n",
    "\"This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. The \"Dataset\" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records.\"\n",
    "\n",
    "I've used [Jason Brownlee's article](https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/) from 2016 as the basis for this article...I wanted to expand a bit on what he did as well as use a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/indian_liver_patient.csv') #read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use all columns except Gender for this tutorial. We could use gender by converting the gender to a numeric value (e.g., 0 for Male, 1 for Female) but for the purproses of this post, we'll just skip this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_use = data\n",
    "del data_to_use['Gender']\n",
    "data_to_use.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Dataset' column is the value we are trying to predict...whether the user has liver disease or not so we'll that as our \"Y\" and the other columns for our \"X\" array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = data_to_use.values\n",
    "\n",
    "Y = values[:,9]\n",
    "X = values[:,0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run our machine learning models, we need to set a random number to use to seed them. This can be any random number that you'd like it to be. Some people like to use a random number generator but for the purposes of this, I'll just set it to 12 (it could just as easily be 1 or 3 or 1023 or any other number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a k-fold validation to evaluate each algorithm and will run through each model with a for loop, running the analysis and then storing the outcomes into the lists we created above. We'll use a 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = []\n",
    "model_names = []\n",
    "models = [('LogReg', LogisticRegression()), \n",
    "          ('SVM', SVC()), \n",
    "          ('DecTree', DecisionTreeClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('LinDisc', LinearDiscriminantAnalysis()),\n",
    "          ('GaussianNB', GaussianNB())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a k-fold validation to evaluate each algorithm and will run through each model with a for loop, running the analysis and then storing the outcomes into the lists we created above. We'll use a 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    k_fold_validation = model_selection.KFold(n_splits=10, random_state=random_seed)\n",
    "    results = model_selection.cross_val_score(model, X, Y, cv=k_fold_validation, scoring='accuracy')\n",
    "    outcome.append(results)\n",
    "    model_names.append(model_name)\n",
    "    output_message = \"%s| Mean=%f STD=%f\" % (model_name, results.mean(), results.std())\n",
    "    print(output_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it looks like the Logistic Regression, Support Vector Machine and Linear Discrimation Analysis methods are providing the best results. If we take a look at a box plot to see what the accuracy is for each cross validation fold, we can see just how good each does relative to each other and their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Machine Learning Model Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(outcome)\n",
    "ax.set_xticklabels(model_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another more complex example (and better) [found here](https://www.kaggle.com/aldemuro/comparing-ml-algorithms-train-accuracy-90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices.\n",
    "As we will see during the course of this chapter, Pandas provides a host of useful tools, methods, and functionality on top of the basic data structures, but nearly everything that follows will require an understanding of what these structures are.\n",
    "Thus, before we go any further, let's introduce these three fundamental Pandas data structures: the ``Series``, ``DataFrame``, and ``Index``.\n",
    "\n",
    "We will start our code sessions with the standard NumPy and Pandas imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas Series Object\n",
    "\n",
    "A Pandas ``Series`` is a one-dimensional array of indexed data.\n",
    "It can be created from a list or array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the output, the Series wraps both a sequence of values and a sequence of indices, which we can access with the values and index attributes. The values are simply a familiar NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``index`` is an array-like object of type ``pd.Index``, which we'll discuss in more detail momentarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see, though, the Pandas ``Series`` is much more general and flexible than the one-dimensional NumPy array that it emulates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Series`` as generalized NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we've seen so far, it may look like the ``Series`` object is basically interchangeable with a one-dimensional NumPy array.\n",
    "The essential difference is the presence of the index: while the Numpy Array has an *implicitly defined* integer index used to access the values, the Pandas ``Series`` has an *explicitly defined* index associated with the values.\n",
    "\n",
    "This explicit index definition gives the ``Series`` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
    "For example, if we wish, we can use strings as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the item access works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use non-contiguous or non-sequential indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=[2, 5, 3, 7])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as specialized dictionary\n",
    "\n",
    "In this way, you can think of a Pandas ``Series`` a bit like a specialization of a Python dictionary.\n",
    "A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a ``Series`` is a structure which maps typed keys to a set of typed values.\n",
    "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas ``Series`` makes it much more efficient than Python dictionaries for certain operations.\n",
    "\n",
    "The ``Series``-as-dictionary analogy can be made even more clear by constructing a ``Series`` object directly from a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, a ``Series`` will be created where the index is drawn from the sorted keys.\n",
    "From here, typical dictionary-style item access can be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a dictionary, though, the ``Series`` also supports array-style operations such as slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['California':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss some of the quirks of Pandas indexing and slicing next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Series objects\n",
    "\n",
    "We've already seen a few ways of constructing a Pandas ``Series`` from scratch; all of them are some version of the following:\n",
    "\n",
    "```python\n",
    ">>> pd.Series(data, index=index)\n",
    "```\n",
    "\n",
    "where ``index`` is an optional argument, and ``data`` can be one of many entities.\n",
    "\n",
    "For example, ``data`` can be a list or NumPy array, in which case ``index`` defaults to an integer sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([2, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(5, index=[100, 200, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``data`` can be a dictionary, in which ``index`` defaults to the sorted dictionary keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({2:'a', 1:'b', 3:'c'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each case, the index can be explicitly set if a different result is preferred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({2:'a', 1:'b', 3:'c'}, index=[3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this case, the ``Series`` is populated only with the explicitly identified keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas DataFrame Object\n",
    "\n",
    "The next fundamental structure in Pandas is the ``DataFrame``.\n",
    "Like the ``Series`` object discussed in the previous section, the ``DataFrame`` can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.\n",
    "We'll now take a look at each of these perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as a generalized NumPy array\n",
    "If a ``Series`` is an analog of a one-dimensional array with flexible indices, a ``DataFrame`` is an analog of a two-dimensional array with both flexible row indices and flexible column names.\n",
    "Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a ``DataFrame`` as a sequence of aligned ``Series`` objects.\n",
    "Here, by \"aligned\" we mean that they share the same index.\n",
    "\n",
    "To demonstrate this, let's first construct a new ``Series`` listing the area of each of the five states discussed in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this along with the ``population`` Series from before, we can use a dictionary to construct a single two-dimensional object containing this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the ``Series`` object, the ``DataFrame`` has an ``index`` attribute that gives access to the index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the ``DataFrame`` has a ``columns`` attribute, which is an ``Index`` object holding the column labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the ``DataFrame`` can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as specialized dictionary\n",
    "\n",
    "Similarly, we can also think of a ``DataFrame`` as a specialization of a dictionary.\n",
    "Where a dictionary maps a key to a value, a ``DataFrame`` maps a column name to a ``Series`` of column data.\n",
    "For example, asking for the ``'area'`` attribute returns the ``Series`` object containing the areas we saw earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the potential point of confusion here: in a two-dimesnional NumPy array, ``data[0]`` will return the first *row*. For a ``DataFrame``, ``data['col0']`` will return the first *column*.\n",
    "Because of this, it is probably better to think about ``DataFrame``s as generalized dictionaries rather than generalized arrays, though both ways of looking at the situation can be useful.\n",
    "We'll explore more flexible means of indexing ``DataFrame``s in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing DataFrame objects\n",
    "\n",
    "A Pandas ``DataFrame`` can be constructed in a variety of ways.\n",
    "Here we'll give several examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a single Series object\n",
    "\n",
    "A ``DataFrame`` is a collection of ``Series`` objects, and a single-column ``DataFrame`` can be constructed from a single ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(population, columns=['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a list of dicts\n",
    "\n",
    "Any list of dictionaries can be made into a ``DataFrame``.\n",
    "We'll use a simple list comprehension to create some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'a': i, 'b': 2 * i}\n",
    "        for i in range(3)]\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if some keys in the dictionary are missing, Pandas will fill them in with ``NaN`` (i.e., \"not a number\") values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a dictionary of Series objects\n",
    "\n",
    "As we saw before, a ``DataFrame`` can be constructed from a dictionary of ``Series`` objects as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'population': population,\n",
    "              'area': area})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a two-dimensional NumPy array\n",
    "\n",
    "Given a two-dimensional array of data, we can create a ``DataFrame`` with any specified column and index names.\n",
    "If omitted, an integer index will be used for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a NumPy structured array\n",
    "\n",
    "We covered structured arrays in Structured Data: NumPy's Structured Arrays in other notebook.\n",
    "A Pandas ``DataFrame`` operates much like a structured array, and can be created directly from one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas Index Object\n",
    "\n",
    "We have seen here that both the ``Series`` and ``DataFrame`` objects contain an explicit *index* that lets you reference and modify data.\n",
    "This ``Index`` object is an interesting structure in itself, and it can be thought of either as an *immutable array* or as an *ordered set* (technically a multi-set, as ``Index`` objects may contain repeated values).\n",
    "Those views have some interesting consequences in the operations available on ``Index`` objects.\n",
    "As a simple example, let's construct an ``Index`` from a list of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index as immutable array\n",
    "\n",
    "The ``Index`` in many ways operates like an array.\n",
    "For example, we can use standard Python indexing notation to retrieve values or slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Index`` objects also have many of the attributes familiar from NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind.size, ind.shape, ind.ndim, ind.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difference between ``Index`` objects and NumPy arrays is that indices are immutable–that is, they cannot be modified via the normal means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This immutability makes it safer to share indices between multiple ``DataFrame``s and arrays, without the potential for side effects from inadvertent index modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index as ordered set\n",
    "\n",
    "Pandas objects are designed to facilitate operations such as joins across datasets, which depend on many aspects of set arithmetic.\n",
    "The ``Index`` object follows many of the conventions used by Python's built-in ``set`` data structure, so that unions, intersections, differences, and other combinations can be computed in a familiar way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 7, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA & indB  # intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA | indB  # union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA ^ indB  # symmetric difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Indexing and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked in detail at methods and tools to access, set, and modify values in NumPy arrays.\n",
    "These included indexing (e.g., ``arr[2, 1]``), slicing (e.g., ``arr[:, 1:5]``), masking (e.g., ``arr[arr > 0]``), fancy indexing (e.g., ``arr[0, [1, 5]]``), and combinations thereof (e.g., ``arr[:, [1, 5]]``).\n",
    "Here we'll look at similar means of accessing and modifying values in Pandas ``Series`` and ``DataFrame`` objects.\n",
    "If you have used the NumPy patterns, the corresponding patterns in Pandas will feel very familiar, though there are a few quirks to be aware of.\n",
    "\n",
    "We'll start with the simple case of the one-dimensional ``Series`` object, and then move on to the more complicated two-dimesnional ``DataFrame`` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection in Series\n",
    "\n",
    "As we saw in the previous section, a ``Series`` object acts in many ways like a one-dimensional NumPy array, and in many ways like a standard Python dictionary.\n",
    "If we keep these two overlapping analogies in mind, it will help us to understand the patterns of data indexing and selection in these arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as dictionary\n",
    "\n",
    "Like a dictionary, the ``Series`` object provides a mapping from a collection of keys to a collection of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use dictionary-like Python expressions and methods to examine the keys/indices and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a' in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Series`` objects can even be modified with a dictionary-like syntax.\n",
    "Just as you can extend a dictionary by assigning to a new key, you can extend a ``Series`` by assigning to a new index value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['e'] = 1.25\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This easy mutability of the objects is a convenient feature: under the hood, Pandas is making decisions about memory layout and data copying that might need to take place; the user generally does not need to worry about these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as one-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ``Series`` builds on this dictionary-like interface and provides array-style item selection via the same basic mechanisms as NumPy arrays – that is, *slices*, *masking*, and *fancy indexing*.\n",
    "Examples of these are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by explicit index\n",
    "data['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by implicit integer index\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking\n",
    "data[(data > 0.3) & (data < 0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy indexing\n",
    "data[['a', 'e']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among these, slicing may be the source of the most confusion.\n",
    "Notice that when slicing with an explicit index (i.e., ``data['a':'c']``), the final index is *included* in the slice, while when slicing with an implicit index (i.e., ``data[0:2]``), the final index is *excluded* from the slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexers: loc, iloc, and ix\n",
    "\n",
    "These slicing and indexing conventions can be a source of confusion.\n",
    "For example, if your ``Series`` has an explicit integer index, an indexing operation such as ``data[1]`` will use the explicit indices, while a slicing operation like ``data[1:3]`` will use the implicit Python-style index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit index when indexing\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit index when slicing\n",
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this potential confusion in the case of integer indexes, Pandas provides some special *indexer* attributes that explicitly expose certain indexing schemes.\n",
    "These are not functional methods, but attributes that expose a particular slicing interface to the data in the ``Series``.\n",
    "\n",
    "First, the ``loc`` attribute allows indexing and slicing that always references the explicit index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third indexing attribute, ``ix``, is a hybrid of the two, and for ``Series`` objects is equivalent to standard ``[]``-based indexing.\n",
    "The purpose of the ``ix`` indexer will become more apparent in the context of ``DataFrame`` objects, which we will discuss in a moment.\n",
    "\n",
    "One guiding principle of Python code is that \"explicit is better than implicit.\"\n",
    "The explicit nature of ``loc`` and ``iloc`` make them very useful in maintaining clean and readable code; especially in the case of integer indexes, I recommend using these both to make code easier to read and understand, and to prevent subtle bugs due to the mixed indexing/slicing convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection in DataFrame\n",
    "\n",
    "Recall that a ``DataFrame`` acts in many ways like a two-dimensional or structured array, and in other ways like a dictionary of ``Series`` structures sharing the same index.\n",
    "These analogies can be helpful to keep in mind as we explore data selection within this structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as a dictionary\n",
    "\n",
    "The first analogy we will consider is the ``DataFrame`` as a dictionary of related ``Series`` objects.\n",
    "Let's return to our example of areas and populations of states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "data = pd.DataFrame({'area':area, 'pop':pop})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual ``Series`` that make up the columns of the ``DataFrame`` can be accessed via dictionary-style indexing of the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, we can use attribute-style access with column names that are strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute-style column access actually accesses the exact same object as the dictionary-style access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area is data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this is a useful shorthand, keep in mind that it does not work for all cases!\n",
    "For example, if the column names are not strings, or if the column names conflict with methods of the ``DataFrame``, this attribute-style access is not possible.\n",
    "For example, the ``DataFrame`` has a ``pop()`` method, so ``data.pop`` will point to this rather than the ``\"pop\"`` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pop is data['pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, you should avoid the temptation to try column assignment via attribute (i.e., use ``data['pop'] = z`` rather than ``data.pop = z``).\n",
    "\n",
    "Like with the ``Series`` objects discussed earlier, this dictionary-style syntax can also be used to modify the object, in this case adding a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['density'] = data['pop'] / data['area']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a preview of the straightforward syntax of element-by-element arithmetic between ``Series`` objects; we'll dig into this further in [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as two-dimensional array\n",
    "\n",
    "As mentioned previously, we can also view the ``DataFrame`` as an enhanced two-dimensional array.\n",
    "We can examine the raw underlying data array using the ``values`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this picture in mind, many familiar array-like observations can be done on the ``DataFrame`` itself.\n",
    "For example, we can transpose the full ``DataFrame`` to swap rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to indexing of ``DataFrame`` objects, however, it is clear that the dictionary-style indexing of columns precludes our ability to simply treat it as a NumPy array.\n",
    "In particular, passing a single index to an array accesses a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and passing a single \"index\" to a ``DataFrame`` accesses a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus for array-style indexing, we need another convention.\n",
    "Here Pandas again uses the ``loc``, ``iloc``, and ``ix`` indexers mentioned earlier.\n",
    "Using the ``iloc`` indexer, we can index the underlying array as if it is a simple NumPy array (using the implicit Python-style index), but the ``DataFrame`` index and column labels are maintained in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, using the ``loc`` indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:'Illinois', :'pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``ix`` indexer allows a hybrid of these two approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ix[:3, :'pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that for integer indices, the ``ix`` indexer is subject to the same potential sources of confusion as discussed for integer-indexed ``Series`` objects.\n",
    "\n",
    "Any of the familiar NumPy-style data access patterns can be used within these indexers.\n",
    "For example, in the ``loc`` indexer we can combine masking and fancy indexing as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.density > 100, ['pop', 'density']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of these indexing conventions may also be used to set or modify values; this is done in the standard way that you might be accustomed to from working with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0, 2] = 90\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build up your fluency in Pandas data manipulation, I suggest spending some time with a simple ``DataFrame`` and exploring the types of indexing, slicing, masking, and fancy indexing that are allowed by these various indexing approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional indexing conventions\n",
    "\n",
    "There are a couple extra indexing conventions that might seem at odds with the preceding discussion, but nevertheless can be very useful in practice.\n",
    "First, while *indexing* refers to columns, *slicing* refers to rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Florida':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such slices can also refer to rows by number rather than by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, direct masking operations are also interpreted row-wise rather than column-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.density > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two conventions are syntactically similar to those on a NumPy array, and while these may not precisely fit the mold of the Pandas conventions, they are nevertheless quite useful in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
